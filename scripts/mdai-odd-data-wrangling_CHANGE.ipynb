{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import mdai\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import PurePath\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('Using CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODDDataset(Dataset):\n",
    "    ''' Makes the exported meta data and images into a torch Dataset\n",
    "    note: this is very similar to <LabelledOCTImagesMDAI>, but better? '''\n",
    "    \n",
    "    def __init__(self, img_path, mask_path, x_set, transform=None, target_transform=None, patch=False):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.x_set = x_set\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.patch = patch\n",
    "       \n",
    "    def __len__(self):\n",
    "        ''' x_set = train/test/val '''\n",
    "        return len(self.x_set)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()  # turns requested index numbers to a list\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.img_path, self.x_set[idx]) + '.png')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.load(os.path.join(self.mask_path, self.x_set[idx]) + '.npy')\n",
    "\n",
    "        '''if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = Image.fromarray(aug['image'])\n",
    "            mask = aug['mask']'''\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            img = F.pad(input=img, pad=(0,0,8,8), mode='constant') # pad so that size is 512 x 768\n",
    "        \n",
    "        if self.target_transform:\n",
    "            mask = self.target_transform(mask)\n",
    "            mask = F.pad(input=mask, pad=(0,0,8,8), mode='constant') # pad so that size is 512 x 768\n",
    "\n",
    "        '''t = T.Compose([T.ToTensor()])# T.Normalize(self.mean, self.std)])\n",
    "        img = t(img) # normalize by mean and std ?\n",
    "        mask = torch.from_numpy(mask).long'''\n",
    "\n",
    "        if self.patch:\n",
    "            img, mask = self.tiles(img, mask)\n",
    "    \n",
    "        return img, mask\n",
    "    \n",
    "    def tiles(self, img, mask):\n",
    "        img_patches =  img.unfold(1, 256, 256).unfold(2, 384, 384)\n",
    "        img_patches  = img_patches.contiguous().view(3,-1, 256, 384) \n",
    "        img_patches = img_patches.permute(1,0,2,3)\n",
    "        mask_patches = mask.unfold(0, 256, 256).unfold(1, 384, 384)\n",
    "        mask_patches = mask_patches.contiguous().view(-1, 256, 384)\n",
    "\n",
    "        return img_patches, mask_patches    \n",
    "\n",
    "'''mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "t_train = A.Compose([A.Resize(496, 768, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n",
    "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
    "                     A.GaussNoise()])\n",
    "t_val = A.Compose([A.Resize(496, 768, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
    "                   A.GridDistortion(p=0.2)])'''\n",
    "\n",
    "train_set = ODDDataset(IMAGE_PATH, MASK_PATH, x_train, transform=T.ToTensor(),target_transform=T.ToTensor())#patch=True)\n",
    "val_set = ODDDataset(IMAGE_PATH, MASK_PATH, x_val, transform=T.ToTensor(), target_transform=T.ToTensor())#, patch=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = ODDDataset(IMAGE_PATH, MASK_PATH, x_train, transform=T.ToTensor(),target_transform=T.ToTensor())#patch=True)\n",
    "val_set = ODDDataset(IMAGE_PATH, MASK_PATH, x_val, transform=T.ToTensor(), target_transform=T.ToTensor())#, patch=True)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "\n",
    "t_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n",
    "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
    "                     A.GaussNoise()])\n",
    "\n",
    "t_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
    "                   A.GridDistortion(p=0.2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy\n",
    "\n",
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=3):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_iou = []; val_acc = []\n",
    "    train_iou = []; train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1 ; not_improve=0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        accuracy = 0\n",
    "        #training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            #training phase\n",
    "            image_tiles, mask_tiles = data\n",
    "            if patch:\n",
    "                bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                mask_tiles = mask_tiles.view(-1, h, w)\n",
    "            \n",
    "            image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
    "            #forward\n",
    "            output = model(image)\n",
    "            loss = criterion(output, mask)\n",
    "            #evaluation metrics\n",
    "            iou_score += mIoU(output, mask)\n",
    "            accuracy += pixel_accuracy(output, mask)\n",
    "            #backward\n",
    "            loss.backward()\n",
    "            optimizer.step() #update weight          \n",
    "            optimizer.zero_grad() #reset gradient\n",
    "            \n",
    "            #step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        else:\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            val_iou_score = 0\n",
    "            #validation loop\n",
    "            with torch.no_grad():\n",
    "                for i, data in enumerate(tqdm(val_loader)):\n",
    "                    #reshape to 9 patches from single image, delete batch size\n",
    "                    image_tiles, mask_tiles = data\n",
    "\n",
    "                    if patch:\n",
    "                        bs, n_tiles, c, h, w = image_tiles.size()\n",
    "\n",
    "                        image_tiles = image_tiles.view(-1,c, h, w)\n",
    "                        mask_tiles = mask_tiles.view(-1, h, w)\n",
    "                    \n",
    "                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n",
    "                    output = model(image)\n",
    "                    #evaluation metrics\n",
    "                    val_iou_score +=  mIoU(output, mask)\n",
    "                    test_accuracy += pixel_accuracy(output, mask)\n",
    "                    #loss\n",
    "                    loss = criterion(output, mask)                                  \n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            #calculatio mean for each batch\n",
    "            train_losses.append(running_loss/len(train_loader))\n",
    "            test_losses.append(test_loss/len(val_loader))\n",
    "\n",
    "\n",
    "            if min_loss > (test_loss/len(val_loader)):\n",
    "                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                decrease += 1\n",
    "                if decrease % 5 == 0:\n",
    "                    print('saving model...')\n",
    "                    torch.save(model, 'Unet-Mobilenet_v2_mIoU-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n",
    "                    \n",
    "\n",
    "            if (test_loss/len(val_loader)) > min_loss:\n",
    "                not_improve += 1\n",
    "                min_loss = (test_loss/len(val_loader))\n",
    "                print(f'Loss Not Decrease for {not_improve} time')\n",
    "                if not_improve == 7:\n",
    "                    print('Loss not decrease for 7 times, Stop Training')\n",
    "                    break\n",
    "            \n",
    "            #iou\n",
    "            val_iou.append(val_iou_score/len(val_loader))\n",
    "            train_iou.append(iou_score/len(train_loader))\n",
    "            train_acc.append(accuracy/len(train_loader))\n",
    "            val_acc.append(test_accuracy/ len(val_loader))\n",
    "            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n",
    "                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n",
    "                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n",
    "                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n",
    "                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n",
    "                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n",
    "                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n",
    "                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n",
    "\n",
    "    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n",
    "    'train_miou' :train_iou, 'val_miou':val_iou,\n",
    "    'train_acc' :train_acc, 'val_acc':val_acc,\n",
    "    'lrs': lrs}\n",
    "    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.63636363636363"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "129/2.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
